{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455f0b56-ebcc-4e38-a72a-b670579d28ce",
   "metadata": {},
   "source": [
    "# Step 4 - Analysis and Reporting\n",
    "\n",
    "So far, we have covered the necessary steps to prepare the construction of your first Machine Learning model. Now it is time to use data and build a our first model. \n",
    "\n",
    "By the end of this module, you will be able to\n",
    "\n",
    "* Train your first Machine Learning model\n",
    "* Indentify the main analysis components when training a Machine Learning model\n",
    "* Generate a report from you model,\n",
    "\n",
    "**NOTE:** This module is intended to provide an introductory approach to machine learning modeling, training and evaluation. This process is covered with more detail and content in the **Machine Learning Methods** courselet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e991dcd-db1a-44e1-b492-e564f23f4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by importing the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e17ee-dc6c-45ed-b920-83c1326c30ca",
   "metadata": {},
   "source": [
    "For this module, we are going to work with the same data from the previous module, the credit approval data from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/). We are going to proceed with data preprocessing. We are not going to detail much as this step was covered in the previous module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f89786-9822-483b-b9d4-915c6e497751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pramonettivega\\AppData\\Local\\Temp\\ipykernel_18536\\2390674034.py:38: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_clean = sklearn.utils.validation.column_or_1d(y_clean,warn=True) # Keeping it as a 1D array. You can ignore the red warning.\n"
     ]
    }
   ],
   "source": [
    "# load our data https://archive.ics.uci.edu/dataset/27/credit+approval\n",
    "credit_approval = fetch_ucirepo(id=27) \n",
    "\n",
    "# DATA PRE-PROCESSING\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "X = credit_approval.data.features \n",
    "y = credit_approval.data.targets\n",
    "\n",
    "# DATA PRE-PROCESSING\n",
    "\n",
    "# Drop missing values\n",
    "X_clean = X.dropna()\n",
    "floats = X_clean.select_dtypes(include=['float']) # We identify the columns with floating point values\n",
    "\n",
    "# Handling outliers \n",
    "threshold = 3\n",
    "valid_rows = [] # This list will store the rows with missing values\n",
    "for x in floats:\n",
    "    z_score = stats.zscore(X_clean[x])\n",
    "    valid = abs(z_score) <= threshold\n",
    "    valid_rows.append(valid)\n",
    "# Combine the outlier masks for all columns\n",
    "combined = pd.concat(valid_rows, axis=1).all(axis=1)\n",
    "combined\n",
    "# Remove rows with outliers\n",
    "X_clean = X_clean[combined]\n",
    "\n",
    "# Dummies\n",
    "categorical = X_clean.select_dtypes(include=['object']).columns# First, we identify the non-numerical features\n",
    "X_dummies = pd.get_dummies(X_clean[categorical], prefix=categorical) # Create dummies\n",
    "X_clean = pd.concat([X_clean, X_dummies], axis=1) # Concatenate dataframes\n",
    "X_clean.drop(categorical, axis=1, inplace=True) # Keep only the dummies, as well as the original continous features\n",
    "\n",
    "# We need to keep the same indices for y\n",
    "y_clean = y.loc[X_clean.index]\n",
    "y_clean = np.where(y_clean==\"+\", 1,0) # Transforming our y_clean into a binary feature\n",
    "y_clean = sklearn.utils.validation.column_or_1d(y_clean,warn=True) # Keeping it as a 1D array. You can ignore the red warning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f13ecf-cae7-4597-8169-23a5722ce5a7",
   "metadata": {},
   "source": [
    "## Splitting our data\n",
    "\n",
    "Once our data is clean and ready to be used, the first thing we have to do is to separate our data into two components: the training and the testing datasets. We use the training set (X_train and y_train) as an input to train a model and develop the parameters of the model. Once we have trained a model, we use our model to make predictions using the testing features dataset (X_test) and compare the predictions (y_pred) with the predictions with the actual values of our target feature (y_test). The Python library [scikit-learn](https://scikit-learn.org/stable/index.html) provides a convenient function for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d68198-c270-4466-940f-7140e5eef04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data - We are using 20% of the data (test_size=0.2) as our testing sample\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec54ae-ec69-4415-ab8a-f5c645ed0492",
   "metadata": {},
   "source": [
    "## Running a model\n",
    "\n",
    "Now it is time to run our first ML model, evaluate it and report results. We are not going to cover multiple essential detail regading the different types of models and the evaluation metrics of these models. Those topics are going to be covered in a different courselet.\n",
    "\n",
    "For this task, we are going to run a simple [Perceptron](https://en.wikipedia.org/wiki/Perceptron) model, which is a binary classifier. We are not going to cover the details of this model (that's a topic for a different courselet), but in general terms, what this model tries to achieve is to find the linear function that better separates our data. We are going to use the predefined [scikit-learn class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f73793d8-8383-4a00-9337-e4fb20a77bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Building the model\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train) # We train the model using our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5457749-eaf1-458a-a663-71ad5498122b",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "Once our model has been trained, the main goal of our process is to make predictions. We can use the method *predict* to create an array of predictions using the features dataset we reserved for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd9363c0-c0f6-4430-ad9c-01fb2691fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71def47-4d03-4f6a-a171-4d8038f240e9",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "Now our model is trained, and we have made predictions with it, is time to see how those predictions compare with the actual values of the y_test array. We can use the *accuracy_score* from scikit-learn to make this evaluation, by taking the division between the number of correct predictions and the size of y_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0551f022-d57f-4f15-93c7-488b9e3bf751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5967741935483871"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scoring\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eeeb96-30fc-424e-9086-58f26c1d0e01",
   "metadata": {},
   "source": [
    "As we can see, our model did not perform greatly. An accuracy of 60% is not much better than a random choice, which by default would give us an accuracy of 50%. There are certainly other models and techniques that could help us obtain a better accuracy. Furthermore, it is also possible that accuracy might not be our target metric, and we care more about other metrics like precision. All of this are topics for a different courselet. What we have tried to accomplish is to give you the opportunity to run your first model and evaluate.\n",
    "\n",
    "Now that we have collected data, preprocessed it, trained a model and evaluated it, and assuming we are confident with the results of our current model, what's next? Our very next step is to deploy it and take actions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff0201-3309-449b-92fb-e4bc1027a8dc",
   "metadata": {},
   "source": [
    "### Hands-On\n",
    "\n",
    "In the following cell, try to achieve a better version of the previous model by doing some feauture selection process. Train a new version of the Perceptron model and compare the accuracy with the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836aa1bf-0bc4-4e3d-9c86-83247c4dd10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
